name: supmap-data
services:
  # ----- D A T A B A S E S -----
  mongodb:
    image: mongo:7.0
    container_name: mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
      MONGO_INITDB_DATABASE: ${MONGO_INITDB_DATABASE}
    ports:
      - "27017:27017"
    volumes:
      - mongodb-data:/data/db
      - ./mongodb/scripts/init-db.js:/docker-entrypoint-initdb.d/init-db.js:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      supmap_data_network:
        ipv4_address: 172.28.1.2

  mongo-express:
    image: mongo-express
    container_name: mongo-express
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      ME_CONFIG_MONGODB_ADMINPASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
      ME_CONFIG_MONGODB_SERVER: mongodb
      ME_CONFIG_BASICAUTH_USERNAME: admin
      ME_CONFIG_BASICAUTH_PASSWORD: admin
    ports:
      - "8081:8081"
    depends_on:
      - mongodb
    restart: unless-stopped
    networks:
      supmap_data_network:
        ipv4_address: 172.28.1.3

  # This service runs the postgres DB used by dagster for run storage, schedule storage,
  # and event log storage. Depending on the hardware you run this Compose on, you may be able
  # to reduce the interval and timeout in the healthcheck to speed up your `docker-compose up` times.
  supmap_data_postgres:
    image: postgres:11
    container_name: supmap_data_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres_user -d postgres_db"]
      interval: 10s
      timeout: 8s
      retries: 5
    networks:
      supmap_data_network:
        ipv4_address: 172.28.1.4

  # ----- D A G S T E R -----

  # This service runs the gRPC server that loads your user code, in both dagster-webserver
  # and dagster-daemon. By setting DAGSTER_CURRENT_IMAGE to its own image, we tell the
  # run launcher to use this same image when launching runs in a new container as well.
  # Multiple containers like this can be deployed separately - each just needs to run on
  # its own port, and have its own entry in the workspace.yaml file that's loaded by the
  # webserver.
  supmap_data_user_code:
    build:
      context: .
      dockerfile: ./Dockerfile_user_code
    container_name: supmap_data_user_code
    image: supmap_data_user_code_image
    restart: always
    environment:
      API_URL: ${API_URL}
      API_LOGIN: ${API_LOGIN}
      API_PASSWORD: ${API_PASSWORD}
      MONGODB_CONNECTION_STRING: ${MONGODB_CONNECTION_STRING}
      MONGODB_DATABASE: ${MONGODB_DATABASE}
      DAGSTER_POSTGRES_USER: ${POSTGRES_USER}
      DAGSTER_POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DAGSTER_POSTGRES_DB: ${POSTGRES_DB}
      DAGSTER_CURRENT_IMAGE: "supmap_data_user_code_image"
    networks:
      supmap_data_network:
        ipv4_address: 172.28.1.5

  # This service runs dagster-webserver, which loads your user code from the user code container.
  # Since our instance uses the QueuedRunCoordinator, any runs submitted from the webserver will be put on
  # a queue and later dequeued and launched by dagster-daemon.
  supmap_data_webserver:
    build:
      context: .
      dockerfile: ./Dockerfile_dagster
    entrypoint:
      - dagster-webserver
      - -h
      - "0.0.0.0"
      - -p
      - "3000"
      - -w
      - workspace.yaml
    container_name: supmap_data_webserver
    expose:
      - "3000"
    ports:
      - "3000:3000"
    environment:
      API_URL: ${API_URL}
      API_LOGIN: ${API_LOGIN}
      API_PASSWORD: ${API_PASSWORD}
      MONGODB_CONNECTION_STRING: ${MONGODB_CONNECTION_STRING}
      MONGODB_DATABASE: ${MONGODB_DATABASE}
      DAGSTER_POSTGRES_USER: ${POSTGRES_USER}
      DAGSTER_POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DAGSTER_POSTGRES_DB: ${POSTGRES_DB}
    volumes: # Make docker client accessible so we can terminate containers from the webserver
      - /var/run/docker.sock:/var/run/docker.sock
      - /tmp/io_manager_storage:/tmp/io_manager_storage
    networks:
      supmap_data_network:
        ipv4_address: 172.28.1.6
    depends_on:
      supmap_data_postgres:
        condition: service_healthy
      supmap_data_user_code:
        condition: service_started

  # This service runs the dagster-daemon process, which is responsible for taking runs
  # off of the queue and launching them, as well as creating runs from schedules or sensors.
  supmap_data_daemon:
    build:
      context: .
      dockerfile: ./Dockerfile_dagster
    entrypoint:
      - dagster-daemon
      - run
    container_name: supmap_data_daemon
    restart: on-failure
    environment:
      API_URL: ${API_URL}
      API_LOGIN: ${API_LOGIN}
      API_PASSWORD: ${API_PASSWORD}
      MONGODB_CONNECTION_STRING: ${MONGODB_CONNECTION_STRING}
      MONGODB_DATABASE: ${MONGODB_DATABASE}
      DAGSTER_POSTGRES_USER: ${POSTGRES_USER}
      DAGSTER_POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DAGSTER_POSTGRES_DB: ${POSTGRES_DB}
    volumes: # Make docker client accessible so we can launch containers using host docker
      - /var/run/docker.sock:/var/run/docker.sock
      - /tmp/io_manager_storage:/tmp/io_manager_storage
    networks:
      supmap_data_network:
        ipv4_address: 172.28.1.7
    depends_on:
      supmap_data_postgres:
        condition: service_healthy
      supmap_data_user_code:
        condition: service_started

networks:
  supmap_data_network:
    driver: bridge
    name: supmap_data_network
    ipam:
      config:
        - subnet: "172.28.1.0/24"

volumes:
  mongodb-data:
